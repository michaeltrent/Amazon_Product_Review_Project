{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Product Review Data Wrangling\n",
    "\n",
    "The purpose of this notebook is to load and clean data from Amazon.com product reviews, ultimately this data will be incorporated into a study to determine how much reviews and/or ratings affect product sales. There are two large JSON files which contain JSON lines for each review,  and product. Both files are too large to simultaneously fit into memory so only a portion of the data will be loaded. Because Amazon product descriptions are often inconsistant among the various vendors, in addition to typical data cleaning tasks (dropping NA's, etc), I'll also run a short algorithm to determine if the datasets contain possible redundant products with only slightly different names (ie \"Casio men's watch GT2HF2\" fitness, vs. \"Casio men's watch GT2HF2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we need to load the various packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from datetime import datetime\n",
    "import gzip\n",
    "import json\n",
    "cDir=os.getcwd()\n",
    "os.chdir(os.path.abspath('C:/Users/micha/Documents/Springboard/Amazon_Product_Review_Project/Data'))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I need to define a couple functions to read in the data. The first function \"parse\" will create a generator that will yield a JSON line from the .json.gz file. The second function will return a pandas data frame with numRow rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path, numRow):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  if i <= numRow: \n",
    "      for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewData = getDF('Home_and_Kitchen_5.json.gz', 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't want to have any products in the dataset that have only a handful of reviews. From working on the feature engineering component I noticed that in a subsample of ~80,000 products I needed at least 80 instances in each category. I also want to remove any products that only exist once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6898955, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.898955e+06</td>\n",
       "      <td>6.898955e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.358473e+00</td>\n",
       "      <td>1.448832e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.131936e+00</td>\n",
       "      <td>5.673527e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.572256e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.420416e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.457222e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.487635e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.538611e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            overall  unixReviewTime\n",
       "count  6.898955e+06    6.898955e+06\n",
       "mean   4.358473e+00    1.448832e+09\n",
       "std    1.131936e+00    5.673527e+07\n",
       "min    1.000000e+00    9.572256e+08\n",
       "25%    4.000000e+00    1.420416e+09\n",
       "50%    5.000000e+00    1.457222e+09\n",
       "75%    5.000000e+00    1.487635e+09\n",
       "max    5.000000e+00    1.538611e+09"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['overall', 'verified', 'reviewTime', 'reviewerID', 'asin',\n",
       "       'reviewerName', 'reviewText', 'summary', 'unixReviewTime', 'vote',\n",
       "       'style', 'image'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = reviewData.groupby('asin')['asin'].filter(lambda x: len(x) > 50)\n",
    "filteredData = reviewData[reviewData['asin'].isin(filtered)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>04 29, 2018</td>\n",
       "      <td>A2J2EILT57HKWR</td>\n",
       "      <td>B00002N601</td>\n",
       "      <td>Gpaw</td>\n",
       "      <td>Cooked a pot roast, mmmm good, nice quality</td>\n",
       "      <td>mmmm good, nice</td>\n",
       "      <td>1524960000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Size:': ' 6 qt'}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>04 23, 2018</td>\n",
       "      <td>AZ5WZ0KJKPFLC</td>\n",
       "      <td>B00002N601</td>\n",
       "      <td>Nom De Plume</td>\n",
       "      <td>Didn't know what size to get but careful readi...</td>\n",
       "      <td>Will Do In A Pinch</td>\n",
       "      <td>1524441600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Size:': ' 4 qt'}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>04 23, 2018</td>\n",
       "      <td>A1TINW4RXWQPNH</td>\n",
       "      <td>B00002N601</td>\n",
       "      <td>Gustavo Q Mastroianni</td>\n",
       "      <td>Worked as expected.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1524441600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Size:': ' 6 qt'}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>04 22, 2018</td>\n",
       "      <td>A39YU2G9YGNXL9</td>\n",
       "      <td>B00002N601</td>\n",
       "      <td>Kelly Rae delo</td>\n",
       "      <td>Nice pressure cooker, love it!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1524355200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Size:': ' 8 qt'}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>04 17, 2018</td>\n",
       "      <td>ASN8LDFAZLX8M</td>\n",
       "      <td>B00002N601</td>\n",
       "      <td>RBH Seattle</td>\n",
       "      <td>Great for hurry-up meals</td>\n",
       "      <td>Fast Cooker!</td>\n",
       "      <td>1523923200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Size:': ' 6 qt'}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0      5.0      True  04 29, 2018  A2J2EILT57HKWR  B00002N601   \n",
       "1      5.0      True  04 23, 2018   AZ5WZ0KJKPFLC  B00002N601   \n",
       "2      5.0      True  04 23, 2018  A1TINW4RXWQPNH  B00002N601   \n",
       "3      5.0      True  04 22, 2018  A39YU2G9YGNXL9  B00002N601   \n",
       "4      5.0      True  04 17, 2018   ASN8LDFAZLX8M  B00002N601   \n",
       "\n",
       "            reviewerName                                         reviewText  \\\n",
       "0                   Gpaw        Cooked a pot roast, mmmm good, nice quality   \n",
       "1           Nom De Plume  Didn't know what size to get but careful readi...   \n",
       "2  Gustavo Q Mastroianni                                Worked as expected.   \n",
       "3         Kelly Rae delo                     Nice pressure cooker, love it!   \n",
       "4            RBH Seattle                           Great for hurry-up meals   \n",
       "\n",
       "              summary  unixReviewTime vote               style image  \n",
       "0     mmmm good, nice      1524960000  NaN  {'Size:': ' 6 qt'}   NaN  \n",
       "1  Will Do In A Pinch      1524441600  NaN  {'Size:': ' 4 qt'}   NaN  \n",
       "2          Five Stars      1524441600  NaN  {'Size:': ' 6 qt'}   NaN  \n",
       "3          Five Stars      1524355200  NaN  {'Size:': ' 8 qt'}   NaN  \n",
       "4        Fast Cooker!      1523923200  NaN  {'Size:': ' 6 qt'}   NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filteredData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4609450, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filteredData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I'll load the product data into a pandas dataframe. Because the JSON data file is so large, the loading process so this takes a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaData = getDF('meta_Home_and_Kitchen.json.gz', 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'tech1', 'description', 'fit', 'title', 'also_buy', 'image',\n",
       "       'tech2', 'brand', 'feature', 'rank', 'also_view', 'main_cat',\n",
       "       'similar_item', 'date', 'price', 'asin', 'details'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def productComparison(productData):\n",
    "    '''This function takes in a dataframe of Amazon data and returns a new data frame with consistent naming convention for \n",
    "    the products'''\n",
    "    #I want to keep an eye on how long this funtion takes to run because I know it's going to be a little slow\n",
    "    startTime = datetime.now()\n",
    "    possibleMatch = []\n",
    "    # Frist identify all the unique product IDs (product_parent) and unique product names (product_title)\n",
    "    uniqueParent = productData['asin'].unique()\n",
    "    uniqueTitle = productData['title'].unique()\n",
    "    #iterate thorugh the unique product IDs to see if the associated product title matches any of the other unique titles. \n",
    "    for product in uniqueParent:\n",
    "        #The titles will change as the data is refined\n",
    "        #uniqueTitle = productData['product_title'].unique()\n",
    "        #First get the title associated with a product ID\n",
    "        try:\n",
    "            prodComp = productData.loc[productData['asin'] == product, 'title'].unique()[0]\n",
    "            #now iterate through the unique titles\n",
    "            for compProd in uniqueTitle:\n",
    "                #No need to make any changes to the dataframe if the product name is the exact same as the comparison string...\n",
    "                if compProd != prodComp:\n",
    "                    #determine both the set ratio and sort ratio\n",
    "                    setRatio = fuzz.token_set_ratio(prodComp, compProd)\n",
    "                    sortRatio = fuzz.token_sort_ratio(prodComp, compProd)\n",
    "                    #If the set ratio and sort ratio both exceed some threshold, then we will update the name of the product in the dataframe\n",
    "                    if setRatio > 80 and sortRatio > 80:\n",
    "                        possibleMatch.append([prodComp, compProd, setRatio, sortRatio])\n",
    "                        productData.loc[productData['title'] == compProd, 'title'] = prodComp\n",
    "        except:\n",
    "            #there will be times that all instances of a where a product title will no longer be in the dataframe (already been changed)\n",
    "            continue\n",
    "        #Reset the product IDs\n",
    "        productData.loc[productData['title'] == prodComp, 'parent'] = product\n",
    "    processTime = datetime.now()-startTime\n",
    "    print(processTime)\n",
    "    return productData, possibleMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Now I can clear the memory of the full review data set.\n",
    "\n",
    "reviewData = []\n",
    "\n",
    "df = pd.merge(filteredData, metaData, how = 'left', on='asin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4903240, 29)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data are merged into one dataframe, I'll clear the reviewData and metaData dataframes to free up space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewData = []\n",
    "metaData = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the large columns from the DF\n",
    "df1 = df.drop(['image_x', 'tech1', 'description', 'image_y', 'tech2', 'also_buy', 'feature', 'also_view', 'similar_item', 'details'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the finished product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "      <th>category</th>\n",
       "      <th>fit</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>rank</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>04 29, 2018</td>\n",
       "      <td>A2J2EILT57HKWR</td>\n",
       "      <td>B00002N601</td>\n",
       "      <td>Gpaw</td>\n",
       "      <td>Cooked a pot roast, mmmm good, nice quality</td>\n",
       "      <td>mmmm good, nice</td>\n",
       "      <td>1524960000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Size:': ' 6 qt'}</td>\n",
       "      <td>[Home &amp; Kitchen, Kitchen &amp; Dining, Cookware, P...</td>\n",
       "      <td></td>\n",
       "      <td>Presto 01241 4-Quart Aluminum Pressure Cooker</td>\n",
       "      <td>Presto</td>\n",
       "      <td>[&gt;#16,941 in Kitchen &amp; Dining (See Top 100 in ...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>September 9, 2003</td>\n",
       "      <td>$23.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>04 29, 2018</td>\n",
       "      <td>A2J2EILT57HKWR</td>\n",
       "      <td>B00002N601</td>\n",
       "      <td>Gpaw</td>\n",
       "      <td>Cooked a pot roast, mmmm good, nice quality</td>\n",
       "      <td>mmmm good, nice</td>\n",
       "      <td>1524960000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Size:': ' 6 qt'}</td>\n",
       "      <td>[Home &amp; Kitchen, Kitchen &amp; Dining, Cookware, P...</td>\n",
       "      <td></td>\n",
       "      <td>Presto 01241 4-Quart Aluminum Pressure Cooker</td>\n",
       "      <td>Presto</td>\n",
       "      <td>[&gt;#16,941 in Kitchen &amp; Dining (See Top 100 in ...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>September 9, 2003</td>\n",
       "      <td>$23.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>04 23, 2018</td>\n",
       "      <td>AZ5WZ0KJKPFLC</td>\n",
       "      <td>B00002N601</td>\n",
       "      <td>Nom De Plume</td>\n",
       "      <td>Didn't know what size to get but careful readi...</td>\n",
       "      <td>Will Do In A Pinch</td>\n",
       "      <td>1524441600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Size:': ' 4 qt'}</td>\n",
       "      <td>[Home &amp; Kitchen, Kitchen &amp; Dining, Cookware, P...</td>\n",
       "      <td></td>\n",
       "      <td>Presto 01241 4-Quart Aluminum Pressure Cooker</td>\n",
       "      <td>Presto</td>\n",
       "      <td>[&gt;#16,941 in Kitchen &amp; Dining (See Top 100 in ...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>September 9, 2003</td>\n",
       "      <td>$23.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>04 23, 2018</td>\n",
       "      <td>AZ5WZ0KJKPFLC</td>\n",
       "      <td>B00002N601</td>\n",
       "      <td>Nom De Plume</td>\n",
       "      <td>Didn't know what size to get but careful readi...</td>\n",
       "      <td>Will Do In A Pinch</td>\n",
       "      <td>1524441600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Size:': ' 4 qt'}</td>\n",
       "      <td>[Home &amp; Kitchen, Kitchen &amp; Dining, Cookware, P...</td>\n",
       "      <td></td>\n",
       "      <td>Presto 01241 4-Quart Aluminum Pressure Cooker</td>\n",
       "      <td>Presto</td>\n",
       "      <td>[&gt;#16,941 in Kitchen &amp; Dining (See Top 100 in ...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>September 9, 2003</td>\n",
       "      <td>$23.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>04 23, 2018</td>\n",
       "      <td>A1TINW4RXWQPNH</td>\n",
       "      <td>B00002N601</td>\n",
       "      <td>Gustavo Q Mastroianni</td>\n",
       "      <td>Worked as expected.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1524441600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Size:': ' 6 qt'}</td>\n",
       "      <td>[Home &amp; Kitchen, Kitchen &amp; Dining, Cookware, P...</td>\n",
       "      <td></td>\n",
       "      <td>Presto 01241 4-Quart Aluminum Pressure Cooker</td>\n",
       "      <td>Presto</td>\n",
       "      <td>[&gt;#16,941 in Kitchen &amp; Dining (See Top 100 in ...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>September 9, 2003</td>\n",
       "      <td>$23.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0      5.0      True  04 29, 2018  A2J2EILT57HKWR  B00002N601   \n",
       "1      5.0      True  04 29, 2018  A2J2EILT57HKWR  B00002N601   \n",
       "2      5.0      True  04 23, 2018   AZ5WZ0KJKPFLC  B00002N601   \n",
       "3      5.0      True  04 23, 2018   AZ5WZ0KJKPFLC  B00002N601   \n",
       "4      5.0      True  04 23, 2018  A1TINW4RXWQPNH  B00002N601   \n",
       "\n",
       "            reviewerName                                         reviewText  \\\n",
       "0                   Gpaw        Cooked a pot roast, mmmm good, nice quality   \n",
       "1                   Gpaw        Cooked a pot roast, mmmm good, nice quality   \n",
       "2           Nom De Plume  Didn't know what size to get but careful readi...   \n",
       "3           Nom De Plume  Didn't know what size to get but careful readi...   \n",
       "4  Gustavo Q Mastroianni                                Worked as expected.   \n",
       "\n",
       "              summary  unixReviewTime vote               style  \\\n",
       "0     mmmm good, nice      1524960000  NaN  {'Size:': ' 6 qt'}   \n",
       "1     mmmm good, nice      1524960000  NaN  {'Size:': ' 6 qt'}   \n",
       "2  Will Do In A Pinch      1524441600  NaN  {'Size:': ' 4 qt'}   \n",
       "3  Will Do In A Pinch      1524441600  NaN  {'Size:': ' 4 qt'}   \n",
       "4          Five Stars      1524441600  NaN  {'Size:': ' 6 qt'}   \n",
       "\n",
       "                                            category fit  \\\n",
       "0  [Home & Kitchen, Kitchen & Dining, Cookware, P...       \n",
       "1  [Home & Kitchen, Kitchen & Dining, Cookware, P...       \n",
       "2  [Home & Kitchen, Kitchen & Dining, Cookware, P...       \n",
       "3  [Home & Kitchen, Kitchen & Dining, Cookware, P...       \n",
       "4  [Home & Kitchen, Kitchen & Dining, Cookware, P...       \n",
       "\n",
       "                                           title   brand  \\\n",
       "0  Presto 01241 4-Quart Aluminum Pressure Cooker  Presto   \n",
       "1  Presto 01241 4-Quart Aluminum Pressure Cooker  Presto   \n",
       "2  Presto 01241 4-Quart Aluminum Pressure Cooker  Presto   \n",
       "3  Presto 01241 4-Quart Aluminum Pressure Cooker  Presto   \n",
       "4  Presto 01241 4-Quart Aluminum Pressure Cooker  Presto   \n",
       "\n",
       "                                                rank     main_cat  \\\n",
       "0  [>#16,941 in Kitchen & Dining (See Top 100 in ...  Amazon Home   \n",
       "1  [>#16,941 in Kitchen & Dining (See Top 100 in ...  Amazon Home   \n",
       "2  [>#16,941 in Kitchen & Dining (See Top 100 in ...  Amazon Home   \n",
       "3  [>#16,941 in Kitchen & Dining (See Top 100 in ...  Amazon Home   \n",
       "4  [>#16,941 in Kitchen & Dining (See Top 100 in ...  Amazon Home   \n",
       "\n",
       "                date   price  \n",
       "0  September 9, 2003  $23.19  \n",
       "1  September 9, 2003  $23.19  \n",
       "2  September 9, 2003  $23.19  \n",
       "3  September 9, 2003  $23.19  \n",
       "4  September 9, 2003  $23.19  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear the orginal merged dataframe form memory.\n",
    "df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data as a csv\n",
    "df1.to_csv('amazonReviewData5000k.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is saved, we can take a close look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a subsample of the reviewData to merge with the metadata rather than working with the entire set\n",
    "\n",
    "reviewDataSample = df1.sample(n = 1500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1500000 entries, 361207 to 4723113\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   overall         1500000 non-null  float64\n",
      " 1   verified        1500000 non-null  bool   \n",
      " 2   reviewTime      1500000 non-null  object \n",
      " 3   reviewerID      1500000 non-null  object \n",
      " 4   asin            1500000 non-null  object \n",
      " 5   reviewerName    1499900 non-null  object \n",
      " 6   reviewText      1499496 non-null  object \n",
      " 7   summary         1499726 non-null  object \n",
      " 8   unixReviewTime  1500000 non-null  int64  \n",
      " 9   vote            179923 non-null   object \n",
      " 10  style           1074456 non-null  object \n",
      " 11  category        1497396 non-null  object \n",
      " 12  fit             1497396 non-null  object \n",
      " 13  title           1497396 non-null  object \n",
      " 14  brand           1497396 non-null  object \n",
      " 15  rank            1497396 non-null  object \n",
      " 16  main_cat        1497396 non-null  object \n",
      " 17  date            1497396 non-null  object \n",
      " 18  price           1497396 non-null  object \n",
      "dtypes: bool(1), float64(1), int64(1), object(16)\n",
      "memory usage: 218.9+ MB\n"
     ]
    }
   ],
   "source": [
    "reviewDataSample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewDataSample.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the sampled data set\n",
    "reviewDataSample.to_csv('amazonReviewData_sample1500k.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets clear all the memory and reload the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv('amazonReviewData_sample1500k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "      <th>category</th>\n",
       "      <th>fit</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>rank</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>05 27, 2016</td>\n",
       "      <td>A1RCEZ4VG7W6Q4</td>\n",
       "      <td>B0000CFN85</td>\n",
       "      <td>Mary Payne Kinnamon</td>\n",
       "      <td>Quality thick paper and worked wonders for my ...</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1464307200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Color:': ' Jumbo -White'}</td>\n",
       "      <td>['Home &amp; Kitchen', 'Kitchen &amp; Dining', 'Bakewa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wilton 415-2505 White Standard 75 Baking Cups,...</td>\n",
       "      <td>Wilton</td>\n",
       "      <td>['&gt;#9,714 in Kitchen &amp; Dining (See Top 100 in ...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>March 10, 2004</td>\n",
       "      <td>$3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>08 15, 2014</td>\n",
       "      <td>A3LTJ22VDCATD1</td>\n",
       "      <td>B001BN8Z2K</td>\n",
       "      <td>Mom of 4</td>\n",
       "      <td>Covers more area in a shorter amount of time. ...</td>\n",
       "      <td>Large head cuts down your work time - twists l...</td>\n",
       "      <td>1408060800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Home &amp; Kitchen', 'Vacuums &amp; Floor Care', 'Va...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miele SBB 400-3 Parquet Twister XL Smooth Floo...</td>\n",
       "      <td>Miele</td>\n",
       "      <td>['&gt;#47,359 in Home &amp; Kitchen (See Top 100 in H...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$57.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>12 30, 2016</td>\n",
       "      <td>A9OHV8NJ03WVH</td>\n",
       "      <td>B0026SPXRY</td>\n",
       "      <td>Susana Pachas</td>\n",
       "      <td>It's great! Easy to assemble and  sturdy it's ...</td>\n",
       "      <td>It's great! Easy to assemble and sturdy it's n...</td>\n",
       "      <td>1483056000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Style Name:': \" BAKER'S RACK\"}</td>\n",
       "      <td>['Home &amp; Kitchen', 'Furniture', 'Kitchen &amp; Din...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whitmor Supreme Sink Shelf - Multiuse Organize...</td>\n",
       "      <td>Whitmor</td>\n",
       "      <td>['&gt;#2,026 in Home &amp; Kitchen (See Top 100 in Ho...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$28.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>09 28, 2015</td>\n",
       "      <td>AT3P07T5RVNTQ</td>\n",
       "      <td>B00ESAR0JW</td>\n",
       "      <td>Hstar13</td>\n",
       "      <td>We haven't had a real oven for over a year now...</td>\n",
       "      <td>This cooks most things pretty well, but you ha...</td>\n",
       "      <td>1443398400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Home &amp; Kitchen', 'Kitchen &amp; Dining', 'Small ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamilton Beach 31103A Countertop Oven with Con...</td>\n",
       "      <td>Hamilton Beach</td>\n",
       "      <td>['&gt;#6,672 in Kitchen &amp; Dining (See Top 100 in ...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>August 9, 2013</td>\n",
       "      <td>$7.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>06 23, 2017</td>\n",
       "      <td>A4I78M7IQPW12</td>\n",
       "      <td>B0074V10JS</td>\n",
       "      <td>Pamela</td>\n",
       "      <td>Nice bedskirt but won't work with a bed that h...</td>\n",
       "      <td>Nice bedskirt</td>\n",
       "      <td>1498176000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Size:': ' Queen/King', 'Color:': ' Burgundy'}</td>\n",
       "      <td>['Home &amp; Kitchen', 'Bedding', 'Bed Skirts']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hdetails Bed Skirts/Elastic Ruffles - Bedding ...</td>\n",
       "      <td>Hdetails</td>\n",
       "      <td>['&gt;#76,184 in Home &amp; Kitchen (See Top 100 in H...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$12.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0      5.0      True  05 27, 2016  A1RCEZ4VG7W6Q4  B0000CFN85   \n",
       "1      5.0      True  08 15, 2014  A3LTJ22VDCATD1  B001BN8Z2K   \n",
       "2      5.0      True  12 30, 2016   A9OHV8NJ03WVH  B0026SPXRY   \n",
       "3      4.0      True  09 28, 2015   AT3P07T5RVNTQ  B00ESAR0JW   \n",
       "4      3.0      True  06 23, 2017   A4I78M7IQPW12  B0074V10JS   \n",
       "\n",
       "          reviewerName                                         reviewText  \\\n",
       "0  Mary Payne Kinnamon  Quality thick paper and worked wonders for my ...   \n",
       "1             Mom of 4  Covers more area in a shorter amount of time. ...   \n",
       "2        Susana Pachas  It's great! Easy to assemble and  sturdy it's ...   \n",
       "3              Hstar13  We haven't had a real oven for over a year now...   \n",
       "4              Pamela   Nice bedskirt but won't work with a bed that h...   \n",
       "\n",
       "                                             summary  unixReviewTime vote  \\\n",
       "0                                         Five Stars      1464307200  NaN   \n",
       "1  Large head cuts down your work time - twists l...      1408060800  NaN   \n",
       "2  It's great! Easy to assemble and sturdy it's n...      1483056000  NaN   \n",
       "3  This cooks most things pretty well, but you ha...      1443398400  NaN   \n",
       "4                                      Nice bedskirt      1498176000  NaN   \n",
       "\n",
       "                                             style  \\\n",
       "0                      {'Color:': ' Jumbo -White'}   \n",
       "1                                              NaN   \n",
       "2                 {'Style Name:': \" BAKER'S RACK\"}   \n",
       "3                                              NaN   \n",
       "4  {'Size:': ' Queen/King', 'Color:': ' Burgundy'}   \n",
       "\n",
       "                                            category  fit  \\\n",
       "0  ['Home & Kitchen', 'Kitchen & Dining', 'Bakewa...  NaN   \n",
       "1  ['Home & Kitchen', 'Vacuums & Floor Care', 'Va...  NaN   \n",
       "2  ['Home & Kitchen', 'Furniture', 'Kitchen & Din...  NaN   \n",
       "3  ['Home & Kitchen', 'Kitchen & Dining', 'Small ...  NaN   \n",
       "4        ['Home & Kitchen', 'Bedding', 'Bed Skirts']  NaN   \n",
       "\n",
       "                                               title           brand  \\\n",
       "0  Wilton 415-2505 White Standard 75 Baking Cups,...          Wilton   \n",
       "1  Miele SBB 400-3 Parquet Twister XL Smooth Floo...           Miele   \n",
       "2  Whitmor Supreme Sink Shelf - Multiuse Organize...         Whitmor   \n",
       "3  Hamilton Beach 31103A Countertop Oven with Con...  Hamilton Beach   \n",
       "4  Hdetails Bed Skirts/Elastic Ruffles - Bedding ...        Hdetails   \n",
       "\n",
       "                                                rank     main_cat  \\\n",
       "0  ['>#9,714 in Kitchen & Dining (See Top 100 in ...  Amazon Home   \n",
       "1  ['>#47,359 in Home & Kitchen (See Top 100 in H...  Amazon Home   \n",
       "2  ['>#2,026 in Home & Kitchen (See Top 100 in Ho...  Amazon Home   \n",
       "3  ['>#6,672 in Kitchen & Dining (See Top 100 in ...  Amazon Home   \n",
       "4  ['>#76,184 in Home & Kitchen (See Top 100 in H...  Amazon Home   \n",
       "\n",
       "             date   price  \n",
       "0  March 10, 2004   $3.43  \n",
       "1             NaN  $57.85  \n",
       "2             NaN  $28.93  \n",
       "3  August 9, 2013   $7.05  \n",
       "4             NaN  $12.99  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several of these columns may be unnecessary. I'm going to explore how many of these columns have a majority of NaNs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall                 0\n",
       "verified                0\n",
       "reviewTime              0\n",
       "reviewerID              0\n",
       "asin                    0\n",
       "reviewerName          193\n",
       "reviewText            504\n",
       "summary               283\n",
       "unixReviewTime          0\n",
       "vote              1320077\n",
       "style              425544\n",
       "category             2604\n",
       "fit               1499553\n",
       "title                2604\n",
       "brand               10268\n",
       "rank                 2604\n",
       "main_cat             4082\n",
       "date               664029\n",
       "price              263237\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since style, fit, and date may not be relevant for analyzing the affect of reviews or overall ratings on purchases, these columns will be dropped. Additionlly, 'vote' appears to be almost entirely missing and the 'overall' column is the rating anyway so 'vote' will also be dropped. With the exception of price, the remaining missing values are small enough that I will happliy drop the rows. It's unfortuntate how many missing values there are for price, because it would make sense for a customer to pay more attention to reviews as price increases. I may need to circle back to try to find a supplemental sample of review to substitute the rows that I will need to drop here, because it is likely not reasonable to impute these with the mean given the range of values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['vote', 'style', 'fit', 'date'], axis = 1)\n",
    "df = df.dropna(axis=0, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1231100 entries, 0 to 1499999\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   overall         1231100 non-null  float64\n",
      " 1   verified        1231100 non-null  bool   \n",
      " 2   reviewTime      1231100 non-null  object \n",
      " 3   reviewerID      1231100 non-null  object \n",
      " 4   asin            1231100 non-null  object \n",
      " 5   reviewerName    1231100 non-null  object \n",
      " 6   reviewText      1231100 non-null  object \n",
      " 7   summary         1231100 non-null  object \n",
      " 8   unixReviewTime  1231100 non-null  int64  \n",
      " 9   category        1231100 non-null  object \n",
      " 10  title           1231100 non-null  object \n",
      " 11  brand           1231100 non-null  object \n",
      " 12  rank            1231100 non-null  object \n",
      " 13  main_cat        1231100 non-null  object \n",
      " 14  price           1231100 non-null  object \n",
      "dtypes: bool(1), float64(1), int64(1), object(12)\n",
      "memory usage: 142.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#Lets take a look at the data now\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks better, but we need price to be a float, and rank to be an int. Updating rank will require some string manipulation to extract the rank within the specific subcategory of Home & Kitchen (i.e. Laundry Bags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First parse the rank on commas and store the result in a new column: rankCat\n",
    "df['rankCat'] = df['rank'].str.split('>#', n = -1, expand = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1285"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:55:58.574257\n"
     ]
    }
   ],
   "source": [
    "#Check for duplicate products\n",
    "checkedData, possibleMatches = productComparison(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hamilton Beach 31103A Countertop Oven with Convection and Rotisserie',\n",
       " 'Hamilton Beach Countertop Oven with Convection and Rotisserie',\n",
       " 100,\n",
       " 95]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possibleMatches[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6721"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(possibleMatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = checkedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to get the ranking of the products for their specific category. This is the second ranking in the list created when we parsed the category ranking. The first element of the list is generally a bracket. We'll standardize the elements using a couple lambda functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rankCat'] = df['rankCat'].apply(lambda x: x[1::] if x[0] == \"['\" else x)\n",
    "df['rankCat'] = df['rankCat'].apply(lambda x: x[1::] if x[0] == \"[\" else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use another lambda function to grab the ranking for the specific category and store it in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['catRank'] = df['rankCat'].apply(lambda x: x[1] if len(x) >= 2 else x[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to grab the first element of the category rank and convert it to an interger\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['catRank'] = df['catRank'].apply(lambda x: x[1::] if x[0] == \"[\" else x)\n",
    "df['Ranking'] = df['catRank'].apply(lambda x: x.split()[0])\n",
    "#Now we should have the rankings but before we convert them to ints we need to drop commas\n",
    "df['Ranking'] = df['Ranking'].str.replace(',', '')\n",
    "df['Ranking'] = df['Ranking'].apply(lambda x: int(x) if x.isdigit() else np.nan)\n",
    "#Now we need to drop any products that don't have rankings.\n",
    "df = df.dropna(axis=0, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1219044 entries, 0 to 1499999\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   overall         1219044 non-null  float64\n",
      " 1   verified        1219044 non-null  bool   \n",
      " 2   reviewTime      1219044 non-null  object \n",
      " 3   reviewerID      1219044 non-null  object \n",
      " 4   asin            1219044 non-null  object \n",
      " 5   reviewerName    1219044 non-null  object \n",
      " 6   reviewText      1219044 non-null  object \n",
      " 7   summary         1219044 non-null  object \n",
      " 8   unixReviewTime  1219044 non-null  int64  \n",
      " 9   category        1219044 non-null  object \n",
      " 10  title           1219044 non-null  object \n",
      " 11  brand           1219044 non-null  object \n",
      " 12  rank            1219044 non-null  object \n",
      " 13  main_cat        1219044 non-null  object \n",
      " 14  price           1219044 non-null  object \n",
      " 15  rankCat         1219044 non-null  object \n",
      " 16  parent          1219044 non-null  object \n",
      " 17  catRank         1219044 non-null  object \n",
      " 18  Ranking         1219044 non-null  float64\n",
      "dtypes: bool(1), float64(2), int64(1), object(15)\n",
      "memory usage: 177.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to convert the price from $xxx.xx to a float of the form xxx.xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df['price'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df['price'].str.replace('$', '')\n",
    "df['price'] = df['price'].str.replace(',', '')\n",
    "#There are some errors in the price data. It seems there are some product descriptions that popped in somehow. To resolve this\n",
    "#I'll replace any long values with 0 so we can drop them later. Anything over 10000.00 will be dropped\n",
    "df['price'] = df['price'].apply(lambda x: str(0) if len(x) > 8 else x)\n",
    "df['price'] = df['price'].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to drop any products that don't have prices].\n",
    "df = df.dropna(axis=0, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1219044 entries, 0 to 1499999\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   overall         1219044 non-null  float64\n",
      " 1   verified        1219044 non-null  bool   \n",
      " 2   reviewTime      1219044 non-null  object \n",
      " 3   reviewerID      1219044 non-null  object \n",
      " 4   asin            1219044 non-null  object \n",
      " 5   reviewerName    1219044 non-null  object \n",
      " 6   reviewText      1219044 non-null  object \n",
      " 7   summary         1219044 non-null  object \n",
      " 8   unixReviewTime  1219044 non-null  int64  \n",
      " 9   category        1219044 non-null  object \n",
      " 10  title           1219044 non-null  object \n",
      " 11  brand           1219044 non-null  object \n",
      " 12  rank            1219044 non-null  object \n",
      " 13  main_cat        1219044 non-null  object \n",
      " 14  price           1219044 non-null  float64\n",
      " 15  rankCat         1219044 non-null  object \n",
      " 16  parent          1219044 non-null  object \n",
      " 17  catRank         1219044 non-null  object \n",
      " 18  Ranking         1219044 non-null  float64\n",
      "dtypes: bool(1), float64(3), int64(1), object(14)\n",
      "memory usage: 177.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that the data is cleaned I want to save it again.\n",
    "\n",
    "df.to_csv('AmazonDataCleaned1500k.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
