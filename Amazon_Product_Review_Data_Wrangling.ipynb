{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to load and clean data from Amazon.com product reviews, ultimately this data will be incorporated into a study to determine how much reviews and/or ratings affect product sales. There are two large JSON files which contain JSON lines for each review,  and product. Both files are too large to simultaneously fit into memory so only a portion of the data will be loaded. Because Amazon product descriptions are often inconsistant among the various vendors, in addition to typical data cleaning tasks (dropping NA's, etc), I'll also run a short algorithm to determine if the datasets contain possible redundant products with only slightly different names (ie \"Casio men's watch GT2HF2\" fitness, vs. \"Casio men's watch GT2HF2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we need to load the various packages\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from datetime import datetime\n",
    "import gzip\n",
    "import json\n",
    "cDir=os.getcwd()\n",
    "os.chdir(os.path.abspath('C:/Users/micha/Documents/Springboard/Unit_7-Data_Wrangling/Data'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I need to define a couple functions to read in the data. The first function \"parse\" will create a generator that will yield a JSON line from the .json.gz file. The second function will return a pandas data frame with numRow rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path, numRow):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  if i <= numRow: \n",
    "      for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewData = getDF('Home_and_Kitchen_5.json.gz', 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I'll load the product data into a pandas dataframe. Because the JSON data file is so large, the loading process so this takes a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaData = getDF('meta_Home_and_Kitchen.json.gz', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'tech1', 'description', 'fit', 'title', 'also_buy', 'image',\n",
       "       'tech2', 'brand', 'feature', 'rank', 'also_view', 'main_cat',\n",
       "       'similar_item', 'date', 'price', 'asin', 'details'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't want to load the JSON data again (it takes about 90 minutes to run through the entire file), so I'll export the data to a csv for ease of loading in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaData.to_csv('metaData.csv')\n",
    "reviewData.to_csv('reviewData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def productComparison(productData):\n",
    "    '''This function takes in a dataframe of Amazon data and returns a new data frame with consistent naming convention for \n",
    "    the products'''\n",
    "    #I want to keep an eye on how long this funtion takes to run because I know it's going to be a little slow\n",
    "    startTime = datetime.now()\n",
    "    possibleMatch = []\n",
    "    # Frist identify all the unique product IDs (product_parent) and unique product names (product_title)\n",
    "    uniqueParent = productData['asin'].unique()\n",
    "    uniqueTitle = productData['title'].unique()\n",
    "    #iterate thorugh the unique product IDs to see if the associated product title matches any of the other unique titles. \n",
    "    for product in uniqueParent:\n",
    "        #The titles will change as the data is refined\n",
    "        #uniqueTitle = productData['product_title'].unique()\n",
    "        #First get the title associated with a product ID\n",
    "        try:\n",
    "            prodComp = productData.loc[productData['asin'] == product, 'title'].unique()[0]\n",
    "            #now iterate through the unique titles\n",
    "            for compProd in uniqueTitle:\n",
    "                #No need to make any changes to the dataframe if the product name is the exact same as the comparison string...\n",
    "                if compProd != prodComp:\n",
    "                    #determine both the set ratio and sort ratio\n",
    "                    setRatio = fuzz.token_set_ratio(prodComp, compProd)\n",
    "                    sortRatio = fuzz.token_sort_ratio(prodComp, compProd)\n",
    "                    #If the set ratio and sort ratio both exceed some threshold, then we will update the name of the product in the dataframe\n",
    "                    if setRatio > 90 and sortRatio > 90:\n",
    "                        possibleMatch.append([prodComp, compProd, setRatio, sortRatio])\n",
    "                        productData.loc[productData['title'] == compProd, 'title'] = prodComp\n",
    "        except:\n",
    "            #there will be times that all instances of a where a product title will no longer be in the dataframe (already been changed)\n",
    "            continue\n",
    "        #Reset the product IDs\n",
    "        productData.loc[productData['title'] == prodComp, 'parent'] = product\n",
    "    processTime = datetime.now()-startTime\n",
    "    print(processTime)\n",
    "    return productData, possibleMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(reviewData, metaData, how = 'left', on='asin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data are merged into one dataframe, I'll clear the reviewData and metaData dataframes to free up space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewData = []\n",
    "metaData = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the large columns from the DF\n",
    "df1 = df.drop(['image_x', 'tech1', 'description', 'image_y', 'tech2', 'also_buy', 'feature', 'also_view', 'similar_item', 'details'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the finished product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "      <th>category</th>\n",
       "      <th>fit</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>rank</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>11 5, 2015</td>\n",
       "      <td>A8LUWTIPU9CZB</td>\n",
       "      <td>0560467893</td>\n",
       "      <td>Linda Fahner</td>\n",
       "      <td>Great product, love it!!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1446681600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Home &amp; Kitchen, Home Dcor, Home Dcor Accents,...</td>\n",
       "      <td></td>\n",
       "      <td>WELLAND Chicago Wall Floating Corner Shelf, 20...</td>\n",
       "      <td>WELLAND</td>\n",
       "      <td>[&gt;#1,037,069 in Home &amp; Kitchen (See Top 100 in...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>05 7, 2015</td>\n",
       "      <td>A3B6GKQQ1JJ167</td>\n",
       "      <td>0560467893</td>\n",
       "      <td>Harry Slaughter</td>\n",
       "      <td>Pretty flimsy, but does the job. If your corne...</td>\n",
       "      <td>Meh</td>\n",
       "      <td>1430956800</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Home &amp; Kitchen, Home Dcor, Home Dcor Accents,...</td>\n",
       "      <td></td>\n",
       "      <td>WELLAND Chicago Wall Floating Corner Shelf, 20...</td>\n",
       "      <td>WELLAND</td>\n",
       "      <td>[&gt;#1,037,069 in Home &amp; Kitchen (See Top 100 in...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>01 22, 2014</td>\n",
       "      <td>A3MCTN65BU7XRA</td>\n",
       "      <td>0681795107</td>\n",
       "      <td>luckyg</td>\n",
       "      <td>So much better than plastic mug types--keeps c...</td>\n",
       "      <td>Recommend</td>\n",
       "      <td>1390348800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Color:': ' Brushed Stainless'}</td>\n",
       "      <td>[Home &amp; Kitchen, Kitchen &amp; Dining, Travel &amp; To...</td>\n",
       "      <td></td>\n",
       "      <td>Stainless Coffee Mug</td>\n",
       "      <td>Timolino</td>\n",
       "      <td>[&gt;#220,715 in Kitchen &amp; Dining (See Top 100 in...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>August 1, 2006</td>\n",
       "      <td>$14.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10 30, 2013</td>\n",
       "      <td>A7JVZFSXVY9RL</td>\n",
       "      <td>0681795107</td>\n",
       "      <td>Nickleen</td>\n",
       "      <td>I like my coffee hot; borderline scorching but...</td>\n",
       "      <td>Not keeping coffee hot for long enough</td>\n",
       "      <td>1383091200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Color:': ' Brushed Stainless'}</td>\n",
       "      <td>[Home &amp; Kitchen, Kitchen &amp; Dining, Travel &amp; To...</td>\n",
       "      <td></td>\n",
       "      <td>Stainless Coffee Mug</td>\n",
       "      <td>Timolino</td>\n",
       "      <td>[&gt;#220,715 in Kitchen &amp; Dining (See Top 100 in...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>August 1, 2006</td>\n",
       "      <td>$14.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>09 20, 2013</td>\n",
       "      <td>A2RQ7VLAK1SHPU</td>\n",
       "      <td>0681795107</td>\n",
       "      <td>Lacemaker427</td>\n",
       "      <td>This mug does only a fair job of keeping coffe...</td>\n",
       "      <td>Leaks like a waterfall when at an angle!</td>\n",
       "      <td>1379635200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Color:': ' Red'}</td>\n",
       "      <td>[Home &amp; Kitchen, Kitchen &amp; Dining, Travel &amp; To...</td>\n",
       "      <td></td>\n",
       "      <td>Stainless Coffee Mug</td>\n",
       "      <td>Timolino</td>\n",
       "      <td>[&gt;#220,715 in Kitchen &amp; Dining (See Top 100 in...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>August 1, 2006</td>\n",
       "      <td>$14.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0      5.0      True   11 5, 2015   A8LUWTIPU9CZB  0560467893   \n",
       "1      3.0      True   05 7, 2015  A3B6GKQQ1JJ167  0560467893   \n",
       "2      5.0      True  01 22, 2014  A3MCTN65BU7XRA  0681795107   \n",
       "3      1.0      True  10 30, 2013   A7JVZFSXVY9RL  0681795107   \n",
       "4      1.0      True  09 20, 2013  A2RQ7VLAK1SHPU  0681795107   \n",
       "\n",
       "      reviewerName                                         reviewText  \\\n",
       "0     Linda Fahner                           Great product, love it!!   \n",
       "1  Harry Slaughter  Pretty flimsy, but does the job. If your corne...   \n",
       "2           luckyg  So much better than plastic mug types--keeps c...   \n",
       "3         Nickleen  I like my coffee hot; borderline scorching but...   \n",
       "4     Lacemaker427  This mug does only a fair job of keeping coffe...   \n",
       "\n",
       "                                    summary  unixReviewTime vote  \\\n",
       "0                                Five Stars      1446681600  NaN   \n",
       "1                                       Meh      1430956800    2   \n",
       "2                                 Recommend      1390348800  NaN   \n",
       "3    Not keeping coffee hot for long enough      1383091200  NaN   \n",
       "4  Leaks like a waterfall when at an angle!      1379635200  NaN   \n",
       "\n",
       "                              style  \\\n",
       "0                               NaN   \n",
       "1                               NaN   \n",
       "2  {'Color:': ' Brushed Stainless'}   \n",
       "3  {'Color:': ' Brushed Stainless'}   \n",
       "4                {'Color:': ' Red'}   \n",
       "\n",
       "                                            category fit  \\\n",
       "0  [Home & Kitchen, Home Dcor, Home Dcor Accents,...       \n",
       "1  [Home & Kitchen, Home Dcor, Home Dcor Accents,...       \n",
       "2  [Home & Kitchen, Kitchen & Dining, Travel & To...       \n",
       "3  [Home & Kitchen, Kitchen & Dining, Travel & To...       \n",
       "4  [Home & Kitchen, Kitchen & Dining, Travel & To...       \n",
       "\n",
       "                                               title     brand  \\\n",
       "0  WELLAND Chicago Wall Floating Corner Shelf, 20...   WELLAND   \n",
       "1  WELLAND Chicago Wall Floating Corner Shelf, 20...   WELLAND   \n",
       "2                               Stainless Coffee Mug  Timolino   \n",
       "3                               Stainless Coffee Mug  Timolino   \n",
       "4                               Stainless Coffee Mug  Timolino   \n",
       "\n",
       "                                                rank     main_cat  \\\n",
       "0  [>#1,037,069 in Home & Kitchen (See Top 100 in...  Amazon Home   \n",
       "1  [>#1,037,069 in Home & Kitchen (See Top 100 in...  Amazon Home   \n",
       "2  [>#220,715 in Kitchen & Dining (See Top 100 in...  Amazon Home   \n",
       "3  [>#220,715 in Kitchen & Dining (See Top 100 in...  Amazon Home   \n",
       "4  [>#220,715 in Kitchen & Dining (See Top 100 in...  Amazon Home   \n",
       "\n",
       "             date   price  \n",
       "0                          \n",
       "1                          \n",
       "2  August 1, 2006  $14.27  \n",
       "3  August 1, 2006  $14.27  \n",
       "4  August 1, 2006  $14.27  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear the orginal merged dataframe form memory.\n",
    "df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data as a csv\n",
    "df1.to_csv('amazonReviewData.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is saved, we can take a close look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7244644 entries, 0 to 7244643\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   overall         float64\n",
      " 1   verified        bool   \n",
      " 2   reviewTime      object \n",
      " 3   reviewerID      object \n",
      " 4   asin            object \n",
      " 5   reviewerName    object \n",
      " 6   reviewText      object \n",
      " 7   summary         object \n",
      " 8   unixReviewTime  int64  \n",
      " 9   vote            object \n",
      " 10  style           object \n",
      " 11  category        object \n",
      " 12  fit             object \n",
      " 13  title           object \n",
      " 14  brand           object \n",
      " 15  rank            object \n",
      " 16  main_cat        object \n",
      " 17  date            object \n",
      " 18  price           object \n",
      "dtypes: bool(1), float64(1), int64(1), object(16)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears the final data set is 7.2 million entries, which is way too large to work with realistically. I'll just use a subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the sampled data set\n",
    "df1.to_csv('amazonReviewData_sample.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets clear all the memory and reload the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv('amazonReviewData_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "      <th>category</th>\n",
       "      <th>fit</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>rank</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>09 13, 2015</td>\n",
       "      <td>A1FLUT4TT4SI7B</td>\n",
       "      <td>B00MNYHJRI</td>\n",
       "      <td>Red Butterfly</td>\n",
       "      <td>Four for decorative detail not five because th...</td>\n",
       "      <td>Nice but...</td>\n",
       "      <td>1442102400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Home &amp; Kitchen', 'Storage &amp; Organization', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&amp;quot;Family, Home, Love&amp;quot; Wood &amp;amp; Meta...</td>\n",
       "      <td>MyGift</td>\n",
       "      <td>['&gt;#78,215 in Home &amp; Kitchen (See Top 100 in H...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$16.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>01 1, 2017</td>\n",
       "      <td>A329DI18H4J51Y</td>\n",
       "      <td>B019AW3N8E</td>\n",
       "      <td>Jkay</td>\n",
       "      <td>I love these. Super soft, fluffy and comfortab...</td>\n",
       "      <td>Love these covers</td>\n",
       "      <td>1483228800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Size:': ' 18 X 18 Inches', 'Color:': ' Ivory'}</td>\n",
       "      <td>['Home &amp; Kitchen', 'Bedding', 'Decorative Pill...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CaliTime Pack of 2 Super Soft Throw Pillow Cov...</td>\n",
       "      <td>CaliTime</td>\n",
       "      <td>['&gt;#163,604 in Home &amp; Kitchen (See Top 100 in ...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$18.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>12 1, 2008</td>\n",
       "      <td>A4I1WJ2MUZV6P</td>\n",
       "      <td>B00005UP2N</td>\n",
       "      <td>KK</td>\n",
       "      <td>I can't add much to what's already been writte...</td>\n",
       "      <td>Excellent product!</td>\n",
       "      <td>1228089600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Home &amp; Kitchen', 'Kitchen &amp; Dining', 'Small ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KitchenAid KSM150PSGR Artisan Series 5-Qt. Sta...</td>\n",
       "      <td>KitchenAid</td>\n",
       "      <td>['&gt;#85 in Kitchen &amp; Dining (See Top 100 in Kit...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>February 11, 2002</td>\n",
       "      <td>$43.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>08 14, 2017</td>\n",
       "      <td>A2MDJLQS61XZUT</td>\n",
       "      <td>B00AX29JPM</td>\n",
       "      <td>Patricia</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1502668800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Size:': ' Twin XL', 'Color:': ' Navy Blue'}</td>\n",
       "      <td>['Home &amp; Kitchen', 'Bedding', 'Bed Skirts']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Superior 1500 Series 100% Microfiber Pleated T...</td>\n",
       "      <td>Superior</td>\n",
       "      <td>['&gt;#373,828 in Home &amp; Kitchen (See Top 100 in ...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$27.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>03 15, 2018</td>\n",
       "      <td>A3BOBH1FYAVRFN</td>\n",
       "      <td>B00GJADRNM</td>\n",
       "      <td>ryan hall</td>\n",
       "      <td>Great pan, fast shipping</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1521072000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Size:': ' 10'}</td>\n",
       "      <td>['Home &amp; Kitchen', 'Kitchen &amp; Dining', 'Cookwa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Starfrit SRFT060312 The Rock Fry Pan, 10-Inch</td>\n",
       "      <td>Starfrit</td>\n",
       "      <td>['&gt;#140,045 in Kitchen &amp; Dining (See Top 100 i...</td>\n",
       "      <td>Amazon Home</td>\n",
       "      <td>November 8, 2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin   reviewerName  \\\n",
       "0      4.0      True  09 13, 2015  A1FLUT4TT4SI7B  B00MNYHJRI  Red Butterfly   \n",
       "1      5.0      True   01 1, 2017  A329DI18H4J51Y  B019AW3N8E           Jkay   \n",
       "2      5.0      True   12 1, 2008   A4I1WJ2MUZV6P  B00005UP2N             KK   \n",
       "3      5.0      True  08 14, 2017  A2MDJLQS61XZUT  B00AX29JPM       Patricia   \n",
       "4      5.0      True  03 15, 2018  A3BOBH1FYAVRFN  B00GJADRNM      ryan hall   \n",
       "\n",
       "                                          reviewText             summary  \\\n",
       "0  Four for decorative detail not five because th...         Nice but...   \n",
       "1  I love these. Super soft, fluffy and comfortab...   Love these covers   \n",
       "2  I can't add much to what's already been writte...  Excellent product!   \n",
       "3                                            Perfect          Five Stars   \n",
       "4                           Great pan, fast shipping          Five Stars   \n",
       "\n",
       "   unixReviewTime vote                                             style  \\\n",
       "0      1442102400  NaN                                               NaN   \n",
       "1      1483228800  NaN  {'Size:': ' 18 X 18 Inches', 'Color:': ' Ivory'}   \n",
       "2      1228089600  NaN                                               NaN   \n",
       "3      1502668800  NaN     {'Size:': ' Twin XL', 'Color:': ' Navy Blue'}   \n",
       "4      1521072000  NaN                                  {'Size:': ' 10'}   \n",
       "\n",
       "                                            category  fit  \\\n",
       "0  ['Home & Kitchen', 'Storage & Organization', '...  NaN   \n",
       "1  ['Home & Kitchen', 'Bedding', 'Decorative Pill...  NaN   \n",
       "2  ['Home & Kitchen', 'Kitchen & Dining', 'Small ...  NaN   \n",
       "3        ['Home & Kitchen', 'Bedding', 'Bed Skirts']  NaN   \n",
       "4  ['Home & Kitchen', 'Kitchen & Dining', 'Cookwa...  NaN   \n",
       "\n",
       "                                               title       brand  \\\n",
       "0  &quot;Family, Home, Love&quot; Wood &amp; Meta...      MyGift   \n",
       "1  CaliTime Pack of 2 Super Soft Throw Pillow Cov...    CaliTime   \n",
       "2  KitchenAid KSM150PSGR Artisan Series 5-Qt. Sta...  KitchenAid   \n",
       "3  Superior 1500 Series 100% Microfiber Pleated T...    Superior   \n",
       "4      Starfrit SRFT060312 The Rock Fry Pan, 10-Inch    Starfrit   \n",
       "\n",
       "                                                rank     main_cat  \\\n",
       "0  ['>#78,215 in Home & Kitchen (See Top 100 in H...  Amazon Home   \n",
       "1  ['>#163,604 in Home & Kitchen (See Top 100 in ...  Amazon Home   \n",
       "2  ['>#85 in Kitchen & Dining (See Top 100 in Kit...  Amazon Home   \n",
       "3  ['>#373,828 in Home & Kitchen (See Top 100 in ...  Amazon Home   \n",
       "4  ['>#140,045 in Kitchen & Dining (See Top 100 i...  Amazon Home   \n",
       "\n",
       "                date   price  \n",
       "0                NaN  $16.99  \n",
       "1                NaN  $18.95  \n",
       "2  February 11, 2002  $43.01  \n",
       "3                NaN  $27.01  \n",
       "4   November 8, 2013     NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several of these columns may be unnecessary. I'm going to explore how many of these columns have a majority of NaNs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.36410</td>\n",
       "      <td>1.447356e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.12181</td>\n",
       "      <td>5.849065e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>9.723456e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.00000</td>\n",
       "      <td>1.419725e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.456445e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.486274e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.537747e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           overall  unixReviewTime\n",
       "count  10000.00000    1.000000e+04\n",
       "mean       4.36410    1.447356e+09\n",
       "std        1.12181    5.849065e+07\n",
       "min        1.00000    9.723456e+08\n",
       "25%        4.00000    1.419725e+09\n",
       "50%        5.00000    1.456445e+09\n",
       "75%        5.00000    1.486274e+09\n",
       "max        5.00000    1.537747e+09"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall              0\n",
       "verified             0\n",
       "reviewTime           0\n",
       "reviewerID           0\n",
       "asin                 0\n",
       "reviewerName         2\n",
       "reviewText           3\n",
       "summary              1\n",
       "unixReviewTime       0\n",
       "vote              8640\n",
       "style             3735\n",
       "category            13\n",
       "fit               9998\n",
       "title               13\n",
       "brand              107\n",
       "rank                13\n",
       "main_cat            19\n",
       "date              4572\n",
       "price             2319\n",
       "parent              13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since style, fit, and date may not be relevant for analyzing the affect of reviews or overall ratings on purchases, these columns will be dropped. Additionlly, 'vote' appears to be almost entirely missing and the 'overall' column is the rating anyway so 'vote' will also be dropped. With the exception of price, the remaining missing values are small enough that I will happliy drop the rows. It's unfortuntate how many missing values there are for price, because it would make sense for a customer to pay more attention to reviews as price increases. I may need to circle back to try to find a supplemental sample of review to substitute the rows that I will need to drop here, because it is likely not reasonable to impute these with the mean given the range of values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['vote', 'style', 'fit', 'date'], axis = 1)\n",
    "df = df.dropna(axis=0, how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7650 entries, 0 to 9999\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   overall         7650 non-null   float64\n",
      " 1   verified        7650 non-null   bool   \n",
      " 2   reviewTime      7650 non-null   object \n",
      " 3   reviewerID      7650 non-null   object \n",
      " 4   asin            7650 non-null   object \n",
      " 5   reviewerName    7650 non-null   object \n",
      " 6   reviewText      7650 non-null   object \n",
      " 7   summary         7650 non-null   object \n",
      " 8   unixReviewTime  7650 non-null   int64  \n",
      " 9   category        7650 non-null   object \n",
      " 10  title           7650 non-null   object \n",
      " 11  brand           7650 non-null   object \n",
      " 12  rank            7650 non-null   object \n",
      " 13  main_cat        7650 non-null   object \n",
      " 14  price           7650 non-null   object \n",
      " 15  parent          7650 non-null   object \n",
      "dtypes: bool(1), float64(1), int64(1), object(13)\n",
      "memory usage: 963.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#Lets take a look at the data now\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks better, but we need price to be a float, and rank to be an int. Updating rank will require some string manipulation to extract the rank within the specific subcategory of Home & Kitchen (i.e. Laundry Bags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#First parse the rank on commas and store the result in a new column: rankCat\n",
    "df['rankCat'] = df['rank'].str.split('>#', n = -1, expand = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for duplicate products\n",
    "checkedData, possibleMatches = productComparison(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
